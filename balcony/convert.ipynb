{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benyamin/miniconda3/envs/smol/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('/work/benyamin/smollm/Kangaroo')\n",
    "\n",
    "\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers_extra import *\n",
    "from kangaroo.kangaroo_model import KangarooModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"/work/benyamin/smollm/hf_checkpoints/Smollm_1B_Frozen_Sorted_Balcony\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type nested_llama to instantiate a model of type llama. This is not supported for all configurations of models and can yield errors.\n",
      "You are using a model of type nested_llama to instantiate a model of type llama. This is not supported for all configurations of models and can yield errors.\n",
      "You are using a model of type nested_llama to instantiate a model of type llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'KangarooModel' object has no attribute 'save_pretrained'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 15\u001b[0m\n\u001b[1;32m      7\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbfloat16\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m KangarooModel(\n\u001b[1;32m     10\u001b[0m     model_name_or_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/work/benyamin/smollm/hf_checkpoints/Smollm_1B_Frozen_Sorted_Balcony\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m     args\u001b[38;5;241m=\u001b[39marguments(),\n\u001b[1;32m     12\u001b[0m     EARLY_STOP_LAYER\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 15\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_pretrained\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./temp/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# final_state = OrderedDict()\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# states = model.model.exit_modules[0].state_dict()\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# for k, v in states.items():\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# adapter_model.load_state_dict(final_state, strict=True)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/smol/lib/python3.11/site-packages/torch/nn/modules/module.py:1935\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1934\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1935\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1936\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1937\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KangarooModel' object has no attribute 'save_pretrained'"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from transformers import LlamaConfig\n",
    "from kangaroo.adapter import AdapterModel\n",
    "import torch\n",
    "from kangaroo.kangaroo_model import KangarooModel\n",
    "class arguments:\n",
    "    dtype='bfloat16'\n",
    "\n",
    "model = KangarooModel(\n",
    "    model_name_or_path='/work/benyamin/smollm/hf_checkpoints/Smollm_1B_Frozen_Sorted_Balcony',\n",
    "    args=arguments(),\n",
    "    EARLY_STOP_LAYER=4\n",
    ")\n",
    "\n",
    "model.save_pretrained('./temp/')\n",
    "\n",
    "# final_state = OrderedDict()\n",
    "# states = model.model.exit_modules[0].state_dict()\n",
    "# for k, v in states.items():\n",
    "#     if k[0] == '0':\n",
    "#         final_state['layers.' + k] = v\n",
    "#     if k[0] == '1':\n",
    "#         final_state['norm.weight'] = v\n",
    "# # print(final_state)\n",
    "# adapter_model_path = '/work/benyamin/smollm/hf_checkpoints/Smollm_1B_Frozen_Sorted_Balcony'\n",
    "# config = LlamaConfig.from_pretrained(os.path.join(adapter_model_path, \"config.json\"), num_hidden_layers=1)\n",
    "\n",
    "# adapter_model = AdapterModel(config, balcony=True)\n",
    "\n",
    "# adapter_model.load_state_dict(final_state, strict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('temp')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "accelerator = Accelerator(mixed_precision='fp16')\n",
    "model = accelerator.prepare(model.adapter_model)\n",
    "accelerator.save_state('./temp', safe_serialization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class arguments:\n",
    "    dtype = 'bfloat16'\n",
    "\n",
    "args = arguments()\n",
    "# args.dtype\n",
    "KangarooModel('/work/benyamin/smollm/hf_checkpoints/Smollm_1B_Frozen_Sorted_Balcony',\n",
    "              '/work/benyamin/smollm/hf_checkpoints/Smollm_1B_Frozen_Sorted_Balcony',\n",
    "              args, EARLY_STOP_LAYER = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "ckpt = torch.load('/work/benyamin/smollm/Kangaroo/balcony/temp/pytorch_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('norm.weight',\n",
       "              tensor([1.0547, 1.1016, 1.0234,  ..., 1.0312, 1.0547, 1.0859], device='cuda:0')),\n",
       "             ('layers.0.self_attn.q_proj.weight',\n",
       "              tensor([[ 0.0002,  0.0015,  0.0220,  ...,  0.0170, -0.0028,  0.0025],\n",
       "                      [-0.0075,  0.0073,  0.0085,  ...,  0.0019,  0.0070, -0.0103],\n",
       "                      [ 0.0043,  0.0015, -0.0172,  ...,  0.0038,  0.0097,  0.0256],\n",
       "                      ...,\n",
       "                      [-0.0002,  0.0039,  0.0118,  ...,  0.0281, -0.0226, -0.0361],\n",
       "                      [-0.0058,  0.0249,  0.0233,  ...,  0.0432,  0.0137, -0.0086],\n",
       "                      [ 0.0311,  0.0093,  0.0087,  ..., -0.0107, -0.0160, -0.0256]],\n",
       "                     device='cuda:0')),\n",
       "             ('layers.0.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0084, -0.0059,  0.0011,  ...,  0.0099, -0.0014,  0.0142],\n",
       "                      [ 0.0002,  0.0255,  0.0018,  ...,  0.0082, -0.0228, -0.0139],\n",
       "                      [-0.0071, -0.0087,  0.0271,  ...,  0.0166, -0.0236, -0.0275],\n",
       "                      ...,\n",
       "                      [-0.0054,  0.0203, -0.0070,  ..., -0.0010, -0.0146, -0.0223],\n",
       "                      [-0.0157, -0.0344,  0.0032,  ...,  0.0376,  0.0276,  0.0096],\n",
       "                      [ 0.0157, -0.0493, -0.0356,  ...,  0.0044, -0.0146, -0.0183]],\n",
       "                     device='cuda:0')),\n",
       "             ('layers.0.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.1689, -0.0090, -0.0469,  ..., -0.0381,  0.1099,  0.0253],\n",
       "                      [ 0.0767, -0.0386,  0.0591,  ..., -0.0154,  0.0767, -0.0291],\n",
       "                      [-0.0728,  0.1177,  0.0118,  ...,  0.0306,  0.0649,  0.0183],\n",
       "                      ...,\n",
       "                      [ 0.0352,  0.0344, -0.0330,  ..., -0.0065,  0.0435,  0.0405],\n",
       "                      [ 0.1226, -0.0099, -0.1367,  ...,  0.0267,  0.0352, -0.1152],\n",
       "                      [ 0.0610,  0.1650, -0.1504,  ...,  0.0142, -0.0085, -0.0288]],\n",
       "                     device='cuda:0')),\n",
       "             ('layers.0.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0776, -0.0062, -0.0588,  ...,  0.0747, -0.0508, -0.0376],\n",
       "                      [ 0.0269, -0.0176, -0.0044,  ..., -0.1328, -0.0049,  0.0190],\n",
       "                      [ 0.0398,  0.0138,  0.0175,  ...,  0.0110, -0.0452,  0.0175],\n",
       "                      ...,\n",
       "                      [-0.0041,  0.0044, -0.0015,  ...,  0.0289,  0.0135,  0.0093],\n",
       "                      [-0.0486,  0.0825, -0.0261,  ...,  0.0113, -0.0439, -0.0135],\n",
       "                      [ 0.1240,  0.0540,  0.0003,  ...,  0.0156,  0.0486,  0.0238]],\n",
       "                     device='cuda:0')),\n",
       "             ('layers.0.input_layernorm.weight',\n",
       "              tensor([1.6641, 1.6719, 1.6641,  ..., 1.6641, 1.5938, 1.6250], device='cuda:0')),\n",
       "             ('layers.0.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0396, -0.0095, -0.0192,  ..., -0.0085,  0.0276, -0.0060],\n",
       "                      [ 0.0299,  0.0014, -0.0452,  ..., -0.0071,  0.0093,  0.0183],\n",
       "                      [ 0.0391, -0.0571,  0.0036,  ..., -0.0371,  0.0128, -0.0189],\n",
       "                      ...,\n",
       "                      [-0.0359, -0.0079, -0.0090,  ..., -0.0014, -0.0170, -0.0315],\n",
       "                      [-0.0369, -0.0386, -0.0106,  ...,  0.0179,  0.0083, -0.0144],\n",
       "                      [-0.0199,  0.0077, -0.0679,  ...,  0.0564,  0.0435, -0.0167]],\n",
       "                     device='cuda:0')),\n",
       "             ('layers.0.mlp.up_proj.weight',\n",
       "              tensor([[-0.0073,  0.0649, -0.0232,  ..., -0.0194, -0.0214, -0.0282],\n",
       "                      [ 0.0029,  0.0200, -0.0461,  ..., -0.0212, -0.0175,  0.0078],\n",
       "                      [-0.0352, -0.0022, -0.0121,  ..., -0.0112,  0.0120,  0.0064],\n",
       "                      ...,\n",
       "                      [ 0.0100,  0.0228, -0.0219,  ..., -0.0021,  0.0430,  0.0381],\n",
       "                      [-0.0522, -0.0133, -0.0383,  ..., -0.0261,  0.0190,  0.0454],\n",
       "                      [ 0.0092,  0.0236, -0.0381,  ...,  0.0098,  0.0003,  0.0006]],\n",
       "                     device='cuda:0')),\n",
       "             ('layers.0.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0136,  0.0322,  0.0003,  ..., -0.0045,  0.0171,  0.0183],\n",
       "                      [-0.0149, -0.0083,  0.0194,  ..., -0.0042,  0.0098, -0.0024],\n",
       "                      [-0.0048, -0.0184,  0.0217,  ...,  0.0247, -0.0139,  0.0237],\n",
       "                      ...,\n",
       "                      [ 0.0255,  0.0410,  0.0033,  ...,  0.0330, -0.0171, -0.0018],\n",
       "                      [-0.0027,  0.0008, -0.0131,  ...,  0.0140,  0.0118, -0.0029],\n",
       "                      [-0.0013, -0.0310,  0.0101,  ..., -0.0110, -0.0297,  0.0184]],\n",
       "                     device='cuda:0')),\n",
       "             ('layers.0.post_attention_layernorm.weight',\n",
       "              tensor([1.8047, 1.8594, 1.8281,  ..., 1.8672, 1.8125, 1.8359], device='cuda:0'))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ckpt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
